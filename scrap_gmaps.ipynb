{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"8f3d601b49a382fd17700b205113e67c\", element=\"f.E0CED4E9E383A50953DC4D1286EB6008.d.3E0283041AA7C62CC64F685CEC7CADB5.e.77\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"8f3d601b49a382fd17700b205113e67c\", element=\"f.E0CED4E9E383A50953DC4D1286EB6008.d.3E0283041AA7C62CC64F685CEC7CADB5.e.78\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"8f3d601b49a382fd17700b205113e67c\", element=\"f.E0CED4E9E383A50953DC4D1286EB6008.d.3E0283041AA7C62CC64F685CEC7CADB5.e.79\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"8f3d601b49a382fd17700b205113e67c\", element=\"f.E0CED4E9E383A50953DC4D1286EB6008.d.3E0283041AA7C62CC64F685CEC7CADB5.e.80\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"8f3d601b49a382fd17700b205113e67c\", element=\"f.E0CED4E9E383A50953DC4D1286EB6008.d.3E0283041AA7C62CC64F685CEC7CADB5.e.81\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"8f3d601b49a382fd17700b205113e67c\", element=\"f.E0CED4E9E383A50953DC4D1286EB6008.d.3E0283041AA7C62CC64F685CEC7CADB5.e.82\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"8f3d601b49a382fd17700b205113e67c\", element=\"f.E0CED4E9E383A50953DC4D1286EB6008.d.3E0283041AA7C62CC64F685CEC7CADB5.e.83\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"8f3d601b49a382fd17700b205113e67c\", element=\"f.E0CED4E9E383A50953DC4D1286EB6008.d.3E0283041AA7C62CC64F685CEC7CADB5.e.84\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"8f3d601b49a382fd17700b205113e67c\", element=\"f.E0CED4E9E383A50953DC4D1286EB6008.d.3E0283041AA7C62CC64F685CEC7CADB5.e.85\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"8f3d601b49a382fd17700b205113e67c\", element=\"f.E0CED4E9E383A50953DC4D1286EB6008.d.3E0283041AA7C62CC64F685CEC7CADB5.e.86\")>]\n",
      "1375\n",
      "10\n",
      "1375\n",
      "20\n",
      "1375\n",
      "30\n",
      "1375\n",
      "40\n",
      "1375\n",
      "50\n",
      "1375\n",
      "60\n",
      "1375\n",
      "70\n",
      "1375\n",
      "80\n",
      "1375\n",
      "90\n",
      "1375\n",
      "100\n",
      "1375\n",
      "110\n",
      "1375\n"
     ]
    }
   ],
   "source": [
    "# Mengimpor library\n",
    "from ast import keyword\n",
    "# from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import chromedriver_binary\n",
    "\n",
    "class Scrapper:\n",
    "    data = {\n",
    "        \"nama\": [],\n",
    "        \"rating_aggregate\": [],\n",
    "        \"jumlah_review\": [],\n",
    "        'review_txt':[],\n",
    "        'rating':[],\n",
    "        'waktu':[]\n",
    "    }\n",
    "    # Instance attribute\n",
    "\n",
    "    def __init__(self, lokasi_list):\n",
    "        for lokasi in lokasi_list[0:5]:\n",
    "            self.halamanLokasi(lokasi)\n",
    "            self.scrapReview()\n",
    "        self.driver.quit()\n",
    "\n",
    "    # Persiapan layar maximize\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    # Persiapan driver Chrome\n",
    "    driver = webdriver.Chrome(\"D:\\Project Pak Arie\\Papeda\\chromedriver-win32\\chromedriver-win32\\chromedriver.exe\")\n",
    "\n",
    "    def halamanLokasi(self,lokasi):\n",
    "        # Persiapan layar maximize\n",
    "        self.driver.get(lokasi)\n",
    "        time.sleep(5)\n",
    "    def scrapReview(self):\n",
    "        time.sleep(10)\n",
    "        nama = self.driver.find_element_by_xpath('//h1[@class=\"DUwDvf lfPIob\"]').text\n",
    "        rating_aggregate = self.driver.find_element_by_xpath('//span[@class=\"ceNzKf\"]').get_attribute('aria-label')\n",
    "        button_review = self.driver.find_element_by_xpath('//div[@class=\"RWPxGd\"]/button[contains(@aria-label, \"Reviews\")]')\n",
    "        # //*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[3]/div/div/button[3]/div[2]/div[2]\n",
    "        button_review.click()\n",
    "        button_review.click()\n",
    "        time.sleep(10)\n",
    "        \n",
    "        jml_review = self.driver.find_element_by_xpath('//div[@class=\"jANrlb \"]/div[@class=\"fontBodySmall\"]').text\n",
    "        jml_review = float(jml_review.replace(' reviews','').replace('.',''))\n",
    "        jml_review = int(jml_review)\n",
    "        self.scrolling(jml_review)\n",
    "        \n",
    "        time.sleep(10)\n",
    "        reviews = self.driver.find_elements(By.XPATH, \"//div[@class='jJc9Ad ']\")\n",
    "        for review in reviews:\n",
    "            more_button = review.find_element_by_xpath('//button[@class=\"w8nwRe kyuRq\"]')\n",
    "            if more_button:\n",
    "                more_button.click()\n",
    "            review_txt = review.find_element_by_xpath('//span[@class=\"wiI7pd\"]').text\n",
    "            rating = review.find_element_by_xpath('//span[@class=\"kvMYJc\"]').get_attribute('aria-label')\n",
    "            waktu = review.find_element_by_xpath('//span[@class=\"rsqaWe\"]').text\n",
    "            self.data[\"nama\"].append(nama)\n",
    "            self.data[\"rating_aggregate\"].append(rating_aggregate)\n",
    "            self.data[\"jumlah_review\"].append(jml_review)\n",
    "            self.data[\"review_txt\"].append(review_txt)\n",
    "            self.data[\"rating\"].append(rating)\n",
    "            self.data[\"waktu\"].append(waktu)\n",
    "        nama_file = str(nama)+\".csv\"\n",
    "        pd.DataFrame(self.data).to_csv(nama_file)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "        # jftiEf fontBodyMedium \n",
    "    def scrolling(self,jml_review):\n",
    "        anchor_el = self.driver.find_elements_by_xpath(\n",
    "            \"//div[@class='jJc9Ad ']\")\n",
    "        print(anchor_el)\n",
    "        print(jml_review)\n",
    "        while True:\n",
    "            # Find elements matching the given XPath\n",
    "            anchor_elements = self.driver.find_elements(By.XPATH, \"//div[@class='jJc9Ad ']\")\n",
    "            up_down = self.driver.find_elements(By.XPATH, \"//div[@class='AyRUI']\")\n",
    "\n",
    "            # Scroll to the last element to load more content if necessary\n",
    "            if anchor_elements:\n",
    "                self.driver.execute_script('arguments[0].scrollIntoView(true);', up_down[2])\n",
    "                time.sleep(5)  # Wait for new content to load\n",
    "                print(len(anchor_elements))\n",
    "                print(jml_review)\n",
    "                \n",
    "                # Break the loop if we have loaded enough reviews\n",
    "                if len(anchor_elements) >= jml_review:\n",
    "                    break\n",
    "            else:\n",
    "                print(\"No more elements found.\")\n",
    "                break\n",
    "\n",
    "\n",
    "daftar_wisata = pd.read_excel('keyword_wisata papua barat.xlsx')\n",
    "hasil = Scrapper(list(daftar_wisata['link']))\n",
    "#[\"wisata bahari\", \"wisata budaya etnik\", \"wisata cagar alam\", \"wisata buru\", \"wisata olahraga\",\n",
    " #\"wisata kuliner\", \"wisata religi\", \"wisata agro\", \"wisata belanja\"]\n",
    "# [\"wisata ekologi\", \"wisata alam\",\n",
    " # \"wisata ruang terbuka hijau\", \"wisata penelitian\",\n",
    " # \"desa wisata\",\"ekowisata\",\"kebun teh\",\"hutan mangrove\", \"gunung\", \"danau\", \"cave\", \"wisata goa\", \"taman\", \"hutan kota\", \"bendungan\",\n",
    " # \"ruang publik terpadu ramah anak\", \"rptra\", \"garden\"])\n",
    " #\"pantai\", \"kolam renang\", \"pemancingan\",\n",
    " #\"candi\", \"museum\", \"desa adat\", \"festival budaya\", \"pusat kesenian\", \"arkeologi\",\n",
    " #\"kebun binatang\", \"kebun raya\", \"taman nasional\",\n",
    " #\"hunting\",\n",
    " #\"stadion\",\n",
    " #\"circuit\", \"diving\", \"panjat tebing\", \"climbing\", \"snorkeling\", \"pasar kuliner\", \"wiskul\", \"restoran\",\n",
    " #\"wisata masjid\", \"wisata gereja\", \"wisata vihara\", \"wisata kelenteng\", \"wisata pura\", \"wisata makam\",\n",
    " \n",
    "# print(hasil.__class__.poptimes)\n",
    "# Yang diganti yang ini C:/FAUZAN/Kerja/Pariwisata/Popular Times/Scraper/\n",
    "pd.DataFrame(hasil.__class__.data).to_csv(\n",
    "    \"final_scrap.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
